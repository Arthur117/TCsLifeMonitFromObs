{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rmax sequence prediction with IBTrACS\n",
    "\n",
    "The goal is to accurately predict Rmax time series of any given TC given a set of parameters of interest from IBTrACS (say n = 8 parameters): Vmax, R34, lon, lat, etc...\n",
    "\n",
    "We will compare several methods: sparse regression (Lasso), analog forecasting (KNN), and Multi-Layer-Perceptron (MLP). We will also test the Chavas and Knaff 2022 model as a reference baseline. Later, we will also use Data Assimilation to answer this challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "# import glob\n",
    "import os.path\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Arrays & Displays\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# # from matplotlib.colors import Normalize\n",
    "# # from matplotlib.colors import ListedColormap\n",
    "# # import matplotlib.cm as cm\n",
    "# import pandas as pd\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable              # Convert arrays to tensors\n",
    "from torch.utils.data import Dataset, DataLoader # Create a Dataset class to combine with DataLoader (= mini batches selection)\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "# Data treatment\n",
    "# import dask as da\n",
    "# from dask.diagnostics import ProgressBar\n",
    "# import zarr\n",
    "# from scipy.interpolate import griddata\n",
    "from datetime import datetime\n",
    "\n",
    "# Custom\n",
    "import dataUtils    as du\n",
    "import pytorchUtils as pu\n",
    "\n",
    "# Statistics\n",
    "from sklearn import linear_model, neighbors\n",
    "\n",
    "# Default parameters\n",
    "mpl.rcParams.update({'font.size': 18})\n",
    "mpl.rcParams['figure.figsize'] = (15, 10)\n",
    "mpl.rcParams['axes.facecolor'] = 'white'\n",
    "mpl.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "1 GPU(s) available\n"
     ]
    }
   ],
   "source": [
    "### Setup device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "print('{} GPU(s) available'.format(torch.cuda.device_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VARIABLES TO CONSIDER\n",
    "'''Initial dataset has 147 variables, so we select only a subset of these'''\n",
    "# storm speed, time, dist2land, usa_r64, usa_r50\n",
    "params_of_interest = ['usa_lon', 'usa_lat', 'usa_wind', 'usa_r34', 'usa_rmw'] \n",
    "input_variables    = ['usa_lon', 'usa_lat', 'usa_wind', 'usa_r34'] \n",
    "target_variable    = ['usa_rmw']\n",
    "additional_info    = ['numobs', 'sid', 'basin', 'name', 'usa_agency', 'iso_time', 'usa_status']\n",
    "\n",
    "### PARAMS\n",
    "PARAMS = {'seq_len':     4, # length of the input time series used to predict y(t)\n",
    "          'n_features':  len(params_of_interest),     # nb of output features\n",
    "          \n",
    "          # Model parameters\n",
    "          'input_size':  5,     # nb of input features\n",
    "          'hidden_size': 20,    # nb of features in hidden state\n",
    "          'num_layers':  2,     # nb of stacked lstm layers\n",
    "          'dropout':     0,   # dropout probability\n",
    "    \n",
    "          'batch_size':  8,     \n",
    "          'n_epochs':    30,     # nb of epochs\n",
    "          'learn_rate':  0.001, # learning rate\n",
    "          \n",
    "          'save_figs':       False,\n",
    "          'feature_scaling': True,\n",
    "         }\n",
    "\n",
    "### PATHS\n",
    "PATHS  = {\n",
    "    # Data\n",
    "    'ibtracs_data': '/home/arthur/data/ibtracs/IBTrACS.NA.v04r00.nc', # '/home/arthur/data/ibtracs/IBTrACS.NA.v04r00.nc'\n",
    "    # Save\n",
    "    'lstm_path':    '/home/arthur/results/TCsLifeMonitFromObs/rmax_seq_pred_ibtracsv/lstmv01.pth', \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OPEN DATASET\n",
    "ds_ibt_raw = xr.open_dataset(PATHS['ibtracs_data'])\n",
    "ds_ibt     = ds_ibt_raw[params_of_interest + additional_info]\n",
    "# ds_ibt_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;usa_rmw&#x27; (date_time: 360)&gt;\n",
       "array([nan, nan, nan, ..., nan, nan, nan], dtype=float32)\n",
       "Coordinates:\n",
       "    time     (date_time) datetime64[ns] 1852-10-03T12:00:00.000040224 ... NaT\n",
       "    lat      (date_time) float32 14.0 14.16 14.3 14.4 14.5 ... nan nan nan nan\n",
       "    lon      (date_time) float32 -67.0 -67.61 -68.2 -68.76 ... nan nan nan nan\n",
       "Dimensions without coordinates: date_time\n",
       "Attributes:\n",
       "    long_name:              Radius of maximum winds (not best tracked)\n",
       "    standard_name:          radius_of_tropical_cyclone_maximum_sustained_wind...\n",
       "    units:                  nmile\n",
       "    valid_min:              1\n",
       "    valid_max:              1000\n",
       "    coverage_content_type:  physicalMeasurement</pre><div class='xr-wrap' hidden><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'usa_rmw'</div><ul class='xr-dim-list'><li><span>date_time</span>: 360</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-feb43f3d-4dd7-4888-93cf-8680c808ccd6' class='xr-array-in' type='checkbox' checked><label for='section-feb43f3d-4dd7-4888-93cf-8680c808ccd6' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>nan nan nan nan nan nan nan nan ... nan nan nan nan nan nan nan nan</span></div><div class='xr-array-data'><pre>array([nan, nan, nan, ..., nan, nan, nan], dtype=float32)</pre></div></div></li><li class='xr-section-item'><input id='section-5fabc655-175e-4a07-b0eb-7c8c8decadeb' class='xr-section-summary-in' type='checkbox'  checked><label for='section-5fabc655-175e-4a07-b0eb-7c8c8decadeb' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>time</span></div><div class='xr-var-dims'>(date_time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-aad0c68e-f627-4572-a79d-d0e68d9301b8' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-aad0c68e-f627-4572-a79d-d0e68d9301b8' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e44c2562-e821-4b7d-badd-2396916886d9' class='xr-var-data-in' type='checkbox'><label for='data-e44c2562-e821-4b7d-badd-2396916886d9' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>time</dd><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>description :</span></dt><dd>Nominally, time steps are 3 hourly, but can be more often since some agencies include extra position (e.g., times near landfall, maximum intensity, etc.)</dd><dt><span>Note :</span></dt><dd>Variable:time can be missing since the tracks are stored in a fixed 2-D grid where tracks have varying lengths</dd><dt><span>coverage_content_type :</span></dt><dd>physicalMeasurement</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;1852-10-03T12:00:00.000040224&#x27;, &#x27;1852-10-03T15:00:00.000040224&#x27;,\n",
       "       &#x27;1852-10-03T18:00:00.000040224&#x27;, ...,                           &#x27;NaT&#x27;,\n",
       "                                 &#x27;NaT&#x27;,                           &#x27;NaT&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lat</span></div><div class='xr-var-dims'>(date_time)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-fc61edd0-16bd-45ff-965f-07e2d9fafa57' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-fc61edd0-16bd-45ff-965f-07e2d9fafa57' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1b08e66b-5e6b-4b9e-ad61-5421fb56a3a1' class='xr-var-data-in' type='checkbox'><label for='data-1b08e66b-5e6b-4b9e-ad61-5421fb56a3a1' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>latitude</dd><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>description :</span></dt><dd>This is merged position based on the position(s) from the various source datasets.</dd><dt><span>Note :</span></dt><dd>Variable:lat can be missing since the tracks are stored in a fixed 2-D grid where tracks have varying lengths</dd><dt><span>coverage_content_type :</span></dt><dd>coordinate</dd></dl></div><div class='xr-var-data'><pre>array([13.999999, 14.162846, 14.3     , ...,       nan,       nan,       nan],\n",
       "      dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lon</span></div><div class='xr-var-dims'>(date_time)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-6fcaa81f-85e6-474e-86d9-84fb98ae1a57' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-6fcaa81f-85e6-474e-86d9-84fb98ae1a57' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-0882d858-0d2b-433b-af2c-25d66dc3795f' class='xr-var-data-in' type='checkbox'><label for='data-0882d858-0d2b-433b-af2c-25d66dc3795f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>longitude</dd><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>description :</span></dt><dd>This is merged position based on the position(s) from the various source datasets.</dd><dt><span>Note :</span></dt><dd>Variable:lon can be missing since the tracks are stored in a fixed 2-D grid where tracks have varying lengths</dd><dt><span>coverage_content_type :</span></dt><dd>coordinate</dd></dl></div><div class='xr-var-data'><pre>array([-67.     , -67.60975, -68.2    , ...,       nan,       nan,       nan],\n",
       "      dtype=float32)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-83f38999-00a7-4c3b-bcca-cff3916a0486' class='xr-section-summary-in' type='checkbox'  checked><label for='section-83f38999-00a7-4c3b-bcca-cff3916a0486' class='xr-section-summary' >Attributes: <span>(6)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>Radius of maximum winds (not best tracked)</dd><dt><span>standard_name :</span></dt><dd>radius_of_tropical_cyclone_maximum_sustained_wind_speed</dd><dt><span>units :</span></dt><dd>nmile</dd><dt><span>valid_min :</span></dt><dd>1</dd><dt><span>valid_max :</span></dt><dd>1000</dd><dt><span>coverage_content_type :</span></dt><dd>physicalMeasurement</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'usa_rmw' (date_time: 360)>\n",
       "array([nan, nan, nan, ..., nan, nan, nan], dtype=float32)\n",
       "Coordinates:\n",
       "    time     (date_time) datetime64[ns] ...\n",
       "    lat      (date_time) float32 ...\n",
       "    lon      (date_time) float32 ...\n",
       "Dimensions without coordinates: date_time\n",
       "Attributes:\n",
       "    long_name:              Radius of maximum winds (not best tracked)\n",
       "    standard_name:          radius_of_tropical_cyclone_maximum_sustained_wind...\n",
       "    units:                  nmile\n",
       "    valid_min:              1\n",
       "    valid_max:              1000\n",
       "    coverage_content_type:  physicalMeasurement"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_ibt_raw.isel(storm=25)['usa_rmw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 394/394 [00:00<00:00, 1104.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples after filtering:  115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### FILTERS\n",
    "# By year\n",
    "start_date = np.datetime64('2000-01-01')\n",
    "fsi        = np.nanargmin(np.abs(ds_ibt['time'][:, 0] - start_date)) # First storm index\n",
    "ds_ibt     = ds_ibt.isel(storm=slice(fsi, -1))\n",
    "# By latitude\n",
    "ds_ibt     = ds_ibt.where(np.abs(ds_ibt['lat']) <= 30)\n",
    "# By removing empty Rmax time series\n",
    "ds_ibt     = ds_ibt.where(ds_ibt['usa_rmw'].notnull().sum(axis=1) > 5)\n",
    "# By removing empty R34 time series\n",
    "ds_ibt     = ds_ibt.where(ds_ibt['usa_r34'].mean(dim='quadrant', skipna=True).notnull()) \n",
    "# By agency\n",
    "ds_ibt     = ds_ibt.where(b'hurdat_atl' in ds_ibt['usa_agency'])\n",
    "# By category\n",
    "ds_ibt     = ds_ibt.where(ds_ibt['usa_wind'].max(dim='date_time', skipna=True) > 64) # >= Cat.1 according to Saffir Simpson scale, 64 is in knts\n",
    "\n",
    "\n",
    "# First average on every quadrant\n",
    "ds_ibt     = ds_ibt.mean(dim='quadrant', skipna=True)\n",
    "\n",
    "# Keep only interesting time series, i.e containing sufficiently long sequences of valid Rmax values\n",
    "for s in tqdm(range(len(ds_ibt['storm']))):\n",
    "    da = ds_ibt.isel(storm=s)['usa_rmw']\n",
    "    if np.max(np.diff(np.where(np.isnan(da)))) < 8: # Count maximum valid sequence and filter it out if less than 1 day\n",
    "        ds_ibt.isel(storm=s)['usa_rmw'] *= np.nan\n",
    "        \n",
    "# Drop NaNs\n",
    "ds_ibt = ds_ibt.dropna(dim='storm', how='all', subset=['usa_rmw']) # Much quicker to drop NaNs only at the end\n",
    "\n",
    "# Convert to m/s and km units\n",
    "ds_ibt['usa_wind'] *= 0.5144\n",
    "ds_ibt['usa_r34']  *= 1.852\n",
    "ds_ibt['usa_rmw']  *= 1.852\n",
    "\n",
    "print(\"Total samples after filtering: \", len(ds_ibt['storm']))\n",
    "\n",
    "# # Find a storm index by ID:\n",
    "# x = ds_ibt_raw['sid'].where(ds_ibt_raw['sid'] == b'2017260N12310')\n",
    "# np.argwhere(x.values==x.values)\n",
    "# MARIA 2017: ds_ibt_raw.isel(storm=2199); ds_ibt.isel(storm=301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (115, 4, 360)\n",
      "y shape: (115, 1, 360)\n"
     ]
    }
   ],
   "source": [
    "### TODO: normalization, train valid test separation\n",
    "# Follow noteboov 02***v02\n",
    "\n",
    "### ZERO PADDING\n",
    "for param in params_of_interest:\n",
    "    ds_ibt[param] = ds_ibt[param].fillna(0)\n",
    "    \n",
    "### PREPARING DATA\n",
    "X_train = np.array(list(ds_ibt[input_variables].data_vars.values()))\n",
    "X_train = np.reshape(X_train, (X_train.shape[1], X_train.shape[0], X_train.shape[2])) # shape (n_storms, n_features, date_time) = (115, 4, 360)\n",
    "y_train = np.array(list(ds_ibt[target_variable].data_vars.values()))\n",
    "y_train = np.reshape(y_train, (y_train.shape[1], y_train.shape[0], y_train.shape[2])) # shape (n_storms, n_features, date_time) = (115, 1, 360)\n",
    "print('X shape:', X_train.shape)\n",
    "print('y shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompleteTimeseriesDataset(Dataset):   \n",
    "    '''\n",
    "    Complete Timeseries Dataset.\n",
    "    Checks that usa_rmw is contains at least a 5-days sequence of non NaN values.\n",
    "    In that case, fills the NaN values with 0 padding, for every variable.\n",
    "    '''\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray,  device: str='cpu'):\n",
    "        self.X          = torch.tensor(X).float()\n",
    "        self.y          = torch.tensor(y).float()\n",
    "        self.device     = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # Select data & Move to GPU if available\n",
    "        input_tensor  = self.X[i, :, :].to(self.device)\n",
    "        target_tensor = self.y[i, :, :].to(self.device)\n",
    "        return input_tensor, target_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape (batch_size, seq_len, n_features): torch.Size([8, 4, 360])\n",
      "Target shape (batch_size, n_features): torch.Size([8, 1, 360])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CompleteTimeseriesDataset(X_train, \n",
    "                                          y_train,\n",
    "                                          device\n",
    "                                         )\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=PARAMS['batch_size'], shuffle=True)\n",
    "X, y = next(iter(train_loader)) # Check\n",
    "print(\"Features shape (batch_size, seq_len, n_features):\", X.shape)\n",
    "print(\"Target shape (batch_size, n_features):\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR_variables = ['usa_lon', 'usa_lat', 'usa_r34']\n",
    "# ds_ibt_LR    = ds_ibt[LR_variables]\n",
    "# ds_ibt_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### CREATE DATASET (Train and test)\n",
    "# # FIRST WE AVERAGE OVER EVERY QUADRANT\n",
    "# # Pre-processing\n",
    "# MU    = {}\n",
    "# SIG   = {}\n",
    "# SCALE = {'usa_wind': 3,\n",
    "#          'usa_rmw':  3, \n",
    "#          'usa_r34':  2,\n",
    "#          'usa_lon':  0.5,\n",
    "#          'usa_lat':  1,\n",
    "# }\n",
    "# if PARAMS['feature_scaling']:\n",
    "#     for param in params_of_interest:\n",
    "#         MU[param]     = float(ds_ibt[param].mean(skipna=True))\n",
    "#         SIG[param]    = float(ds_ibt[param].std(skipna=True))\n",
    "#         ds_ibt[param] = SCALE[param] * ((ds_ibt[param] - MU[param]) / SIG[param])\n",
    "\n",
    "# # Separate train and test set\n",
    "# sep1 = int(0.6 * len(ds_ibt['storm'])) # 60% train, 20% valid, 20% test\n",
    "# sep2 = int(0.8 * len(ds_ibt['storm']))\n",
    "# ds_train, ds_valid, ds_test = ds_ibt.isel(storm=slice(None, sep1)), ds_ibt.isel(storm=slice(sep1, sep2)),  ds_ibt.isel(storm=slice(sep2, None))\n",
    "# print('Train set: %i storms;  '%len(ds_train['storm']), 'Valid set: %i storms'%len(ds_valid['storm']), 'Test set: %i storms'%len(ds_test['storm']))\n",
    "\n",
    "# # Create Dataset\n",
    "# X_train, y_train = du.create_dataset(ds_train, params_of_interest, PARAMS)\n",
    "# X_valid, y_valid = du.create_dataset(ds_valid, params_of_interest, PARAMS)\n",
    "# X_test, y_test   = du.create_dataset(ds_test,  params_of_interest, PARAMS)\n",
    "# print('Shape of predictors matrix X_train: ', np.asarray(X_train).shape)\n",
    "# print('Shape of targets matrix y_train: ', np.asarray(y_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_valid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32259/1273427212.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                           \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                          )\n\u001b[0;32m----> 9\u001b[0;31m valid_dataset = pu.ShortTimeseriesDataset(X_valid, \n\u001b[0m\u001b[1;32m     10\u001b[0m                                           \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                           \u001b[0mPARAMS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_valid' is not defined"
     ]
    }
   ],
   "source": [
    "# Open Datasets\n",
    "# Train, valid, and test sets are moved to GPU if available\n",
    "train_dataset = pu.ShortTimeseriesDataset(X_train, \n",
    "                                          y_train,\n",
    "                                          PARAMS['n_features'],\n",
    "                                          PARAMS['seq_len'],\n",
    "                                          device\n",
    "                                         )\n",
    "valid_dataset = pu.ShortTimeseriesDataset(X_valid, \n",
    "                                          y_valid,\n",
    "                                          PARAMS['n_features'],\n",
    "                                          PARAMS['seq_len'],\n",
    "                                          device\n",
    "                                         )\n",
    "test_dataset  = pu.ShortTimeseriesDataset(X_test, \n",
    "                                          y_test,\n",
    "                                          PARAMS['n_features'],\n",
    "                                          PARAMS['seq_len'],\n",
    "                                          device\n",
    "                                         )\n",
    "\n",
    "# DataLoader\n",
    "# torch.manual_seed(99)\n",
    "train_loader = DataLoader(train_dataset, batch_size=PARAMS['batch_size'], shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=PARAMS['batch_size'], shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=PARAMS['batch_size'], shuffle=False)\n",
    "\n",
    "X, y = next(iter(train_loader)) # Check\n",
    "print(\"Features shape (batch_size, seq_len, n_features):\", X.shape)\n",
    "print(\"Target shape (batch_size, n_features):\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare model\n",
    "# Normally, LSTM1 handles batch_size\n",
    "model = pu.LSTM1(num_classes=PARAMS['n_features'], \n",
    "                 input_size=PARAMS['input_size'],\n",
    "                 hidden_size=PARAMS['hidden_size'],\n",
    "                 num_layers=PARAMS['num_layers'],\n",
    "                 seq_len=PARAMS['seq_len'],\n",
    "                 dropout=PARAMS['dropout'],\n",
    ")\n",
    "print(model)\n",
    "print('Trainable parameters:', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "# Move to GPU if available\n",
    "model.to(device)\n",
    "\n",
    "# Loss function, optimizer\n",
    "loss_function = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer     = torch.optim.Adam(model.parameters(), lr=PARAMS['learn_rate']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_loader, model, loss_function, optimizer):\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss  = 0\n",
    "    model.train()\n",
    "\n",
    "    for X, y in data_loader:\n",
    "        output = model(X)\n",
    "        loss = loss_function(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    # print(f\"Train loss: {avg_loss}\")\n",
    "    return avg_loss\n",
    "\n",
    "def valid_model(data_loader, model, loss_function):\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss  = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            output = model(X)\n",
    "            total_loss += loss_function(output, y).item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    # print(f\"Valid loss: {avg_loss}\")\n",
    "    return avg_loss\n",
    "    \n",
    "def test_model(data_loader, model, loss_function):\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss  = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            output = model(X)\n",
    "            total_loss += loss_function(output, y).item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    # print(f\"Test loss: {avg_loss}\")\n",
    "    return avg_loss\n",
    "\n",
    "def predict(data_loader, model):\n",
    "    '''\n",
    "    CAVEAT: Model is put onto CPU in this function.\n",
    "    '''\n",
    "    output = torch.tensor([])\n",
    "    \n",
    "    model.cpu()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, _ in data_loader:\n",
    "            y_star = model(X)\n",
    "            output = torch.cat((output, y_star), 0)\n",
    "\n",
    "    return output\n",
    "\n",
    "print(\"Untrained valid loss\\n--------\")\n",
    "best_vl = valid_model(valid_loader, model, loss_function)\n",
    "print(best_vl)\n",
    "print()\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "test_loss  = []\n",
    "for ix_epoch in tqdm(range(PARAMS['n_epochs'])):\n",
    "    tl = train_model(train_loader, model, loss_function, optimizer=optimizer)\n",
    "    vl = valid_model(valid_loader, model, loss_function)\n",
    "    train_loss.append(tl)\n",
    "    valid_loss.append(vl)\n",
    "    test_loss.append(test_model(test_loader, model, loss_function))\n",
    "    if ix_epoch % (PARAMS['n_epochs'] // 4) == 0:\n",
    "        print(f\"Epoch {ix_epoch} / {PARAMS['n_epochs']}\\n---------\")\n",
    "        print(f\"Train loss: {tl}\\nValid loss: {vl}\\n\")\n",
    "    # Save model\n",
    "    if vl < best_vl:\n",
    "        torch.save(model.state_dict(), PATHS['lstm_path'])\n",
    "\n",
    "# Plot\n",
    "plt.plot(train_loss, label='Train loss', color='tab:blue')\n",
    "plt.plot(valid_loss, label='Valid loss', color='tab:red')\n",
    "plt.plot(test_loss,  label='Test loss',  color='tab:olive')\n",
    "plt.xlabel('Epoch');plt.ylabel('Loss')\n",
    "plt.legend(loc='lower left');plt.grid()\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(PATHS['lstm_path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### METRICS\n",
    "# Linear regression\n",
    "lrg = linear_model.LinearRegression()\n",
    "lrg.fit(X_train, y_train)\n",
    "print('==> LINEAR \\nR2: ', lrg.score(X_test, y_test))\n",
    "print('RMSE Vmax (m/s): ', round(du.rmse(du.inverse_scale_normalize(lrg.predict(X_test)[:, 2], MU, SIG, SCALE, 'usa_wind'), du.inverse_scale_normalize(np.asarray(y_test)[:, 2], MU, SIG, SCALE, 'usa_wind')), 2))\n",
    "print('RMSE R34  (km) : ', round(du.rmse(du.inverse_scale_normalize(lrg.predict(X_test)[:, 3], MU, SIG, SCALE, 'usa_r34'), du.inverse_scale_normalize(np.asarray(y_test)[:, 3], MU, SIG, SCALE, 'usa_r34')), 2))\n",
    "print('RMSE Rmax (km) : ', round(du.rmse(du.inverse_scale_normalize(lrg.predict(X_test)[:, 4], MU, SIG, SCALE, 'usa_rmw'), du.inverse_scale_normalize(np.asarray(y_test)[:, 4], MU, SIG, SCALE, 'usa_rmw')), 2))\n",
    "\n",
    "# LSTM\n",
    "test_dataset_cpu = pu.ShortTimeseriesDataset(X_test, y_test, PARAMS['n_features'], PARAMS['seq_len'])\n",
    "test_loader_cpu  = DataLoader(test_dataset_cpu,  batch_size=PARAMS['batch_size'], shuffle=False)\n",
    "preds            = predict(test_loader_cpu, model).cpu().detach().numpy()\n",
    "print('\\n==> LSTM')\n",
    "print('RMSE Vmax (m/s): ', round(du.rmse(du.inverse_scale_normalize(preds[:, 2], MU, SIG, SCALE, 'usa_wind'), du.inverse_scale_normalize(np.asarray(y_test)[:, 2], MU, SIG, SCALE, 'usa_wind')), 2))\n",
    "print('RMSE R34  (km) : ', round(du.rmse(du.inverse_scale_normalize(preds[:, 3], MU, SIG, SCALE, 'usa_r34'), du.inverse_scale_normalize(np.asarray(y_test)[:, 3], MU, SIG, SCALE, 'usa_r34')), 2))\n",
    "print('RMSE Rmax (km) : ', round(du.rmse(du.inverse_scale_normalize(preds[:, 4], MU, SIG, SCALE, 'usa_rmw'), du.inverse_scale_normalize(np.asarray(y_test)[:, 4], MU, SIG, SCALE, 'usa_rmw')), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose test sample\n",
    "ds_im        = ds_test.isel(storm=slice(6, 7))\n",
    "\n",
    "# Prepare inference data\n",
    "X_im, y_im   = du.create_dataset(ds_im,  params_of_interest, PARAMS)\n",
    "im_dataset   = pu.ShortTimeseriesDataset(X_im, \n",
    "                                          y_im,\n",
    "                                          PARAMS['n_features'],\n",
    "                                          PARAMS['seq_len'],\n",
    "                                         )\n",
    "im_loader    = DataLoader(im_dataset,  batch_size=PARAMS['batch_size'], shuffle=False)\n",
    "# Inference\n",
    "y_pred       = predict(im_loader, model)\n",
    "# Target\n",
    "y_im         = np.array(y_im)\n",
    "\n",
    "# Plot\n",
    "for i, param in enumerate(params_of_interest):\n",
    "    feature = y_pred[:, i].cpu().detach().numpy()\n",
    "    feature = du.inverse_scale_normalize(feature, MU, SIG, SCALE, param)\n",
    "    target  = y_im[:, i]\n",
    "    target  = du.inverse_scale_normalize(target,  MU, SIG, SCALE, param)\n",
    "    lin_fea = du.inverse_scale_normalize(lrg.predict(X_im)[:, i], MU, SIG, SCALE, param)\n",
    "    plt.title(param, weight='bold')\n",
    "    plt.plot(target,  label='Data', linewidth=3, color='tab:blue')\n",
    "    plt.plot(feature, label='LSTM', color='tab:pink')\n",
    "    plt.plot(lin_fea, label='Regression', color='tab:green', linestyle=':')\n",
    "    plt.legend(loc='upper left');plt.grid()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paramProfiles",
   "language": "python",
   "name": "paramprofiles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
