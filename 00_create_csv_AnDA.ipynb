{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CSV files for AnDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "# import glob\n",
    "import os.path\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "\n",
    "# Arrays & Displays\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "\n",
    "# Data treatment\n",
    "from datetime import datetime\n",
    "\n",
    "# Custom\n",
    "import functions as f\n",
    "import dataUtils as du\n",
    "\n",
    "# Default parameters\n",
    "mpl.rcParams.update({'font.size': 18})\n",
    "mpl.rcParams['figure.figsize'] = (15, 10)\n",
    "mpl.rcParams['axes.facecolor'] = 'white'\n",
    "mpl.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VARIABLES TO CONSIDER\n",
    "'''Initial dataset has 147 variables, so we select only a subset of these'''\n",
    "# storm speed, time, dist2land, usa_r64, usa_r50\n",
    "params_of_interest = ['usa_lon', 'usa_lat', 'usa_wind', 'usa_r34', 'usa_rmw', 'storm_speed', 'storm_dir', 'numobs'] \n",
    "additional_info    = ['sid', 'basin', 'name', 'usa_agency', 'iso_time', 'usa_status']\n",
    "\n",
    "### PARAMS\n",
    "PARAMS = {'fcor_boost' : 1,         \n",
    "         }\n",
    "\n",
    "### PATHS\n",
    "PATHS  = {\n",
    "    # Data\n",
    "    'ibtracs_data': '/home/arthur/data/ibtracs/IBTrACS.ALL.v04r00.nc', # '/home/arthur/data/ibtracs/IBTrACS.NA.v04r00.nc'\n",
    "    # Save\n",
    "    'save_path':     '/home/arthur/results/TCsLifeMonitFromObs/descriptive_stats/',\n",
    "    'save_csv_path': '/home/arthur/scripts/TCsLifeMonitFromObs/AnDA/AnDA_data/IBTrACS_V5/',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OPEN DATASET\n",
    "ds_ibt_raw = xr.open_dataset(PATHS['ibtracs_data'])\n",
    "\n",
    "ds_ibt                  = ds_ibt_raw[params_of_interest]\n",
    "ds_ibt[additional_info] = ds_ibt_raw[additional_info].astype(str, copy=False) # Convert byte arrays to strings\n",
    "# ds_ibt_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### FILTERS\n",
    "# # Convert to m/s and km units\n",
    "# ds_ibt['usa_wind']    *= 0.5144\n",
    "# ds_ibt['storm_speed'] *= 0.5144\n",
    "# ds_ibt['usa_r34']     *= 1.852\n",
    "# ds_ibt['usa_rmw']     *= 1.852\n",
    "\n",
    "# ### 1) FILTERS BY YEAR, EMPTY R34, CATEGORY, RMAX INTERESTING TIME SERIES\n",
    "# # By year\n",
    "# start_date = np.datetime64('2000-01-01')\n",
    "# fsi        = np.nanargmin(np.abs(ds_ibt['time'][:, 0] - start_date)) # First storm index\n",
    "# ds_ibt     = ds_ibt.isel(storm=slice(fsi, -1))\n",
    "# # Average by quadrant (R34 assumption) \n",
    "# # ds_ibt     = ds_ibt.mean(dim='quadrant', skipna=True) # Relax this assumption to study the asymmetry\n",
    "# # By category\n",
    "# for s in tqdm(range(len(ds_ibt['storm']))):\n",
    "#     da = ds_ibt.isel(storm=s)['usa_wind']\n",
    "#     if da.max(dim='date_time', skipna=True) < 33: # >= Cat.1 according to Saffir Simpson scale, 64 is in knts\n",
    "#         ds_ibt.isel(storm=s)['usa_wind'] *= np.nan  \n",
    "\n",
    "# # # Keep only interesting time series, i.e containing sufficiently long sequences of valid Rmax values\n",
    "# for s in tqdm(range(len(ds_ibt['storm']))):\n",
    "#     da = ds_ibt.isel(storm=s)['usa_rmw']\n",
    "#     # Longest valid sequence\n",
    "#     # if np.max(np.diff(np.where(np.isnan(da)))) < 8: # Count maximum valid sequence and filter it out if less than 1 day\n",
    "#     #     ds_ibt.isel(storm=s)['usa_rmw'] *= np.nan\n",
    "#     # Number of valid values\n",
    "#     if np.count_nonzero(~np.isnan(da)) < 24: # Count the number otimestep_since_17msf valid usa_rmw values and filter it out if less than 24 values\n",
    "#         ds_ibt.isel(storm=s)['usa_rmw'] *= np.nan   \n",
    "# # Drop NaNs\n",
    "# ds_ibt = ds_ibt.dropna(dim='storm', how='all', subset=['usa_wind']) # Much quicker to drop NaNs only at the end\n",
    "# ds_ibt = ds_ibt.dropna(dim='storm', how='all', subset=['usa_rmw']) \n",
    "# ds_ibt = ds_ibt.dropna(dim='storm', how='all', subset=['usa_r34'])\n",
    "\n",
    "# # Add Time step since 17.5 m/s have been achieved\n",
    "# ds_ibt['timestep_since_17ms'] = ds_ibt['usa_lon'] * 0\n",
    "# ds_ibt['initial_r17']         = ds_ibt['numobs'] * 0\n",
    "# for s in tqdm(range(len(ds_ibt.storm))):\n",
    "#     ds = ds_ibt.isel(storm=s)\n",
    "#     timestep_of_17ms = int(np.where(ds['usa_wind'] > 17.5)[0][0])\n",
    "#     initial_r17      = float(ds_ibt.isel(storm=-1)['usa_r34'].mean(dim='quadrant', skipna=True)[timestep_of_17ms + 1]) # t + 1 to ensure a value is defined\n",
    "#     ds_ibt['timestep_since_17ms'][s] = ds.date_time - timestep_of_17ms\n",
    "#     ds_ibt['initial_r17'][s]         = initial_r17  \n",
    "\n",
    "# print(\"Total samples after (1): \", len(ds_ibt['storm']))\n",
    "\n",
    "# ### 2) FINAL DATASET\n",
    "# ### Keep longest valid sequence if it represents more than 60% of the TC life cycle\n",
    "# # Both for RMW and R34\n",
    "# life_cyc_percent_thresh = 0.6\n",
    "\n",
    "# for s in tqdm(range(len(ds_ibt['storm']))):\n",
    "#         ds      = ds_ibt.isel(storm=s)\n",
    "#         # Compute life cycle length\n",
    "#         cyc_len = np.where(np.isnan(ds['usa_lat']))[0][0]\n",
    "#         for param in ['usa_r34', 'usa_rmw']:\n",
    "#         # for param in ['usa_rmw']:\n",
    "#             # Compute length of longest valid sequence\n",
    "#             val_len = np.max(np.diff(np.concatenate(([0], np.where(np.isnan(ds[param]))[0]), axis=0)))\n",
    "#             if val_len < life_cyc_percent_thresh * cyc_len:\n",
    "#                 # print('Index {}, Cyc_len = {}, val_len = {}'.format(s, cyc_len, val_len))\n",
    "#                 ds[param] *= np.nan\n",
    "                \n",
    "# ds_ibt = ds_ibt.dropna(dim='storm', how='all', subset=['usa_rmw']) \n",
    "# ds_ibt = ds_ibt.dropna(dim='storm', how='all', subset=['usa_r34'])\n",
    "\n",
    "# print(\"Total samples after (2): \", len(ds_ibt['storm'])) \n",
    "\n",
    "# ### 3) ADD CORIOLIS\n",
    "# ds_ibt['fcor'] = f.coriolis(np.abs(ds_ibt['usa_lat'])) * PARAMS['fcor_boost']\n",
    "                \n",
    "# ### 4) FLIP TCs of Southern hemisphere\n",
    "# ### Take the symmetric with respect to Equator\n",
    "# ### So storm_dir = PI - storm_dir\n",
    "# ds_ibt.where(ds_ibt['lat'] < 0)['storm_dir'] = 180 - ds_ibt['storm_dir']\n",
    "# # Then project to (u, v) ref.\n",
    "# ds_ibt['u_trans'] = ds_ibt['storm_speed'] * np.sin(np.deg2rad(ds_ibt['storm_dir']))\n",
    "# ds_ibt['v_trans'] = ds_ibt['storm_speed'] * np.cos(np.deg2rad(ds_ibt['storm_dir']))\n",
    "# # plt.hist(np.array(ds_ibt['u_trans']).flatten()) # Check gaussianity\n",
    "\n",
    "# ### 5) COMPUTE RMAX_CK22\n",
    "# ds_ibt['rmax_ck22'] = f.get_rmax_ck22(\n",
    "#     Vmax=ds_ibt['usa_wind'], R17=ds_ibt['usa_r34'], fcor=f.coriolis(np.abs(ds_ibt['usa_lat'])), \n",
    "#     intercept=0.459, coef1=0.00534, coef2=-0.00337\n",
    "# ) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### SAVE\n",
    "# ds_ibt.to_netcdf(PATHS['save_path'] + 'ds_ibtracs_ALL.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### OPEN\n",
    "ds_ibt = xr.open_dataset(PATHS['save_path'] + 'ds_ibtracs_ALL.nc')\n",
    "# ds_ibt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILTERS\n",
    "# Rmax selection\n",
    "# ds_ibt = ds_ibt.where(ds_ibt['usa_rmw'] < 50, drop=True)\n",
    "# Latitude selection\n",
    "ds_ibt = ds_ibt.where(ds_ibt['fcor'] < f.coriolis(30), drop=True)\n",
    "# Outliers\n",
    "# ds_ibt = ds_ibt.where(ds_ibt['name'] != 'NADINE', drop=True) # NADINE (2012) reintensifies at the end of its life cycle, leading to very high timestep since 17.5 m/s\n",
    "# NB: this is not the only example: Florence, Dorian, Winston... \n",
    "# Thus,  one possibility is to constrain this delay to be not too long:\n",
    "# ds_ibt = ds_ibt.where(ds_ibt['timestep_since_17ms'] < 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091b940f28a945f7936dc882212cacce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/564 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### COMPUTE V_STAR AND T_STAR AND CALIBRATE ALL THE STORMS ON THESE\n",
    "list_of_vars = ['usa_lon', 'usa_lat', 'usa_wind', 'usa_r34', 'mean_r34', 'usa_rmw', 'storm_dir', 'storm_speed', 'lon', 'lat', 'timestep_since_17ms',\\\n",
    "               'basin', 'fcor', 'u_trans', 'v_trans', 'rmax_ck22', 'mean_rmax_ck22',\n",
    "               ]\n",
    "\n",
    "### COMPUTE v*, and t*\n",
    "ds_ibt['v_star']     = ds_ibt['usa_wind'].max(dim='date_time', skipna=True)\n",
    "v_star_idxs          = ds_ibt['usa_wind'].argmax(dim='date_time', skipna=True)\n",
    "ds_ibt['t_star_idx'] = v_star_idxs # i.e the first index where usa_wind = LMI, no matter the NaNs\n",
    "ds_ibt['t_star']     = ds_ibt['time'][:, v_star_idxs]\n",
    "t34_idxs             = np.abs(ds_ibt['timestep_since_17ms']).argmin(dim='date_time', skipna=True)\n",
    "ds_ibt['t34_idx']    = t34_idxs # i.e the first index where usa_wind = 34kts, no matter the NaNs\n",
    "# Add Time step since v_star has been achieved\n",
    "ds_ibt['timestep_since_v_star'] = ds_ibt['usa_lon'] * 0\n",
    "for s in tqdm(range(len(ds_ibt.storm))):\n",
    "    ds = ds_ibt.isel(storm=s)\n",
    "    timestep_of_v_star = int(np.where(ds['usa_wind'] == float(ds['v_star']))[0][0])\n",
    "    ds_ibt['timestep_since_v_star'][s] = ds.date_time - timestep_of_v_star\n",
    "\n",
    "# Delete sequences\n",
    "ds_temp  = ds_ibt.where(ds_ibt['t_star_idx'] - ds_ibt['t34_idx'] >= 20, drop=True) # Delete sequences where end idx is lower than seq_len\n",
    "    \n",
    "# Select between 34kts and V*\n",
    "ds_final = ds_temp.where((ds_temp['timestep_since_17ms'] >= 0) & (ds_temp['timestep_since_v_star'] <= 0), drop=True)\n",
    "\n",
    "# Mean R34 and Rmax_CK22\n",
    "ds_final['mean_r34']       = ds_final['usa_r34'].mean(dim='quadrant', skipna=True) # mean R34\n",
    "ds_final['mean_rmax_ck22'] = ds_final['rmax_ck22'].mean(dim='quadrant', skipna=True) # mean R34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a78960a827841f99c679dae89e7e285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/scripts/TCsLifeMonitFromObs/functions.py:23: RuntimeWarning: invalid value encountered in power\n",
      "  return (0.5 * Ck_Cd) ** (1 / (2 - Ck_Cd))\n"
     ]
    }
   ],
   "source": [
    "### ASSIGN CK/CD\n",
    "ds_final['ER11']  = ds_final['usa_rmw'] * 1000 * ds_final['usa_wind'] / (ds_final['mean_r34'] * 1000 * 17.5 + 0.5 * ds_final['fcor'] * ((ds_final['mean_r34'] * 1000) ** 2))\n",
    "ds_final['ck_cd'] = ds_final['usa_rmw'] * 0\n",
    "for s in tqdm(range(len(ds_final.storm))):\n",
    "    ds = ds_final.isel(storm=s)\n",
    "    for dt in range(len(ds.date_time)):\n",
    "        dst   = ds.isel(date_time=dt)\n",
    "        if dst['ER11'].notnull():\n",
    "            ck_cd = f.fit_Ck_Cd_eq38(float(dst['ER11']))\n",
    "            if ck_cd < 2.5:\n",
    "                ds_final['ck_cd'][s, dt] = float(ck_cd)\n",
    "            else:\n",
    "                ds_final['ck_cd'][s, dt] = np.nan\n",
    "        else:\n",
    "            ds_final['ck_cd'][s, dt] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898e5044d20c44c3be6289149317ffa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### ASSIGN BASIN AS STRING\n",
    "ds_final['basin_as_str'] = ds_final['basin'][:, 0]\n",
    "for s in tqdm(range(len(ds_final.storm))):\n",
    "    ds = ds_final.isel(storm=s)\n",
    "    for dt in range(len(ds.date_time)):\n",
    "        bsn = ds['basin'][dt].item()\n",
    "        if bsn != '':\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    ds_final['basin_as_str'][s] = bsn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e499e11e31b4ae6b5f7fb721f20783b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ### SAVE CSV FILES\n",
    "# def create_csv_file(ds, final_params=['usa_wind', 'usa_rmw', 'mean_rmax_ck22', 'mean_r34', 'fcor', 'u_trans', 'v_trans']):\n",
    "#     # print('Creating dataset...')\n",
    "#     X   = [] # shape (n_time, n_params)\n",
    "#     fin_par_with_diff = final_params + ['{}_diff'.format(p) for p in final_params]\n",
    "        \n",
    "#     # Add derivatives\n",
    "#     for p in final_params:\n",
    "#         ds['{}_diff'.format(p)]     = ds[p] * np.nan\n",
    "#         ds['{}_diff'.format(p)][1:] = ds[p].diff(dim='date_time')\n",
    "#     # Get only valid stime steps\n",
    "#     ds         = ds.dropna(dim='date_time', subset=fin_par_with_diff)\n",
    "\n",
    "#     # Add to X and Y dataset\n",
    "#     da         = ds[fin_par_with_diff].to_array().transpose()\n",
    "#     for t in range(len(da['date_time'])):\n",
    "#         X.append(da[t, :].values)\n",
    "    \n",
    "#     # Convert to arrays\n",
    "#     X   = np.array(X)\n",
    "#     return X\n",
    "\n",
    "# ### SAVE CSV FILES - With Ck/Cd\n",
    "# for s in tqdm(range(len(ds_final.storm))):\n",
    "#     ds         = ds_final.isel(storm=s)\n",
    "#     nme        = ds['name'].where(ds['name'].notnull(), drop=True)[0].item()\n",
    "#     sid        = ds['sid'].where(ds['sid'].notnull(), drop=True)[0].item()\n",
    "#     filename   = nme + '_' + sid\n",
    "#     X_TC       = create_csv_file(ds, final_params=['usa_wind', 'usa_rmw', 'mean_rmax_ck22', 'mean_r34', 'fcor', 'u_trans', 'v_trans'])\n",
    "#     if len(X_TC) > 0:\n",
    "#         X_TC       = X_TC[:, [0, 1, 2, 3, 4, 5, 6]] # Select parameters\n",
    "#         df         = pd.DataFrame(X_TC)\n",
    "#         df.columns =  ['Vmax', 'Rmax_IBT', 'Rmax_CK22', 'R34', 'fcor', 'u_trans', 'v_trans']\n",
    "#         df.to_csv(PATHS['save_csv_path'] + filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paramProfiles",
   "language": "python",
   "name": "paramprofiles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
