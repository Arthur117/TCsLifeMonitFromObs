{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vmax tracking using IBTrACS\n",
    "\n",
    "v06: Just to save csv files with the mean Ck/Cd computed using IBTrACS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "# import glob\n",
    "import os.path\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "# Arrays & Displays\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# # from matplotlib.colors import Normalize\n",
    "# # from matplotlib.colors import ListedColormap\n",
    "# # import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable              # Convert arrays to tensors\n",
    "from torch.utils.data import Dataset, DataLoader # Create a Dataset class to combine with DataLoader (= mini batches selection)\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Data treatment\n",
    "# import dask as da\n",
    "# from dask.diagnostics import ProgressBar\n",
    "# import zarr\n",
    "# from scipy.interpolate import griddata\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Custom\n",
    "import functions as f\n",
    "\n",
    "# Statistics\n",
    "from sklearn import linear_model, neighbors\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "# Default parameters\n",
    "mpl.rcParams.update({'font.size': 18})\n",
    "mpl.rcParams['figure.figsize'] = (15, 10)\n",
    "mpl.rcParams['axes.facecolor'] = 'white'\n",
    "mpl.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "1 GPU(s) available\n"
     ]
    }
   ],
   "source": [
    "### Setup device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "print('{} GPU(s) available'.format(torch.cuda.device_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VARIABLES TO CONSIDER\n",
    "'''Initial dataset has 147 variables, so we select only a subset of these'''\n",
    "# storm speed, time, dist2land, usa_r64, usa_r50\n",
    "params_of_interest = ['usa_lon', 'usa_lat', 'usa_wind', 'usa_r34', 'usa_rmw', 'storm_speed', 'storm_dir', 'mean_ck_cd'] \n",
    "additional_info    = ['numobs', 'sid', 'basin', 'name', 'usa_agency', 'iso_time', 'usa_status']\n",
    "\n",
    "### PARAMS\n",
    "PARAMS = {'fcor_boost' : 1,         \n",
    "         }\n",
    "\n",
    "### PATHS\n",
    "PATHS  = {\n",
    "    # Data\n",
    "    # 'ibtracs_data': '/home/arthur/data/ibtracs/IBTrACS.NA.v04r00.nc', # '/home/arthur/data/ibtracs/IBTrACS.NA.v04r00.nc'\n",
    "    'ibtracs_data': '/home/arthur/results/TCsLifeMonitFromObs/kalman/ds_ibt_ALL_with_mean_ck_cd',\n",
    "    # Save\n",
    "    'save_path':     '/home/arthur/results/TCsLifeMonitFromObs/kalman/',\n",
    "    'save_csv_path': '/home/arthur/scripts/TCsLifeMonitFromObs/AnDA/AnDA_data/IBTrACS_V3/',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OPEN DATASET\n",
    "ds_ibt_raw = xr.open_dataset(PATHS['ibtracs_data'])\n",
    "ds_ibt     = ds_ibt_raw[params_of_interest + additional_info]\n",
    "# ds_ibt_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 502/502 [00:00<00:00, 920.72it/s]\n",
      "100%|███████████████████████████████████████| 502/502 [00:00<00:00, 1671.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples after (1):  148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 148/148 [00:00<00:00, 965.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples after (2):  148\n"
     ]
    }
   ],
   "source": [
    "### FILTERS\n",
    "# Convert to m/s and km units\n",
    "ds_ibt['usa_wind']    *= 0.5144\n",
    "ds_ibt['storm_speed'] *= 0.5144\n",
    "ds_ibt['usa_r34']     *= 1.852\n",
    "ds_ibt['usa_rmw']     *= 1.852\n",
    "\n",
    "### 1) FILTERS BY YEAR, EMPTY R34, CATEGORY, RMAX INTERESTING TIME SERIES\n",
    "# By year\n",
    "start_date = np.datetime64('2000-01-01')\n",
    "fsi        = np.nanargmin(np.abs(ds_ibt['time'][:, 0] - start_date)) # First storm index\n",
    "ds_ibt     = ds_ibt.isel(storm=slice(fsi, -1))\n",
    "# Average by quadrant (R34 assumption)\n",
    "ds_ibt     = ds_ibt.mean(dim='quadrant', skipna=True)\n",
    "# By category\n",
    "for s in tqdm(range(len(ds_ibt['storm']))):\n",
    "    da = ds_ibt.isel(storm=s)['usa_wind']\n",
    "    if da.max(dim='date_time', skipna=True) < 33: # >= Cat.1 according to Saffir Simpson scale, 64 is in knts\n",
    "        ds_ibt.isel(storm=s)['usa_wind'] *= np.nan  \n",
    "\n",
    "# # Keep only interesting time series, i.e containing sufficiently long sequences of valid Rmax values\n",
    "for s in tqdm(range(len(ds_ibt['storm']))):\n",
    "    da = ds_ibt.isel(storm=s)['usa_rmw']\n",
    "    # Longest valid sequence\n",
    "    # if np.max(np.diff(np.where(np.isnan(da)))) < 8: # Count maximum valid sequence and filter it out if less than 1 day\n",
    "    #     ds_ibt.isel(storm=s)['usa_rmw'] *= np.nan\n",
    "    # Number of valid values\n",
    "    if np.count_nonzero(~np.isnan(da)) < 24: # Count the number of valid usa_rmw values and filter it out if less than 24 values\n",
    "        ds_ibt.isel(storm=s)['usa_rmw'] *= np.nan   \n",
    "# Drop NaNs\n",
    "ds_ibt = ds_ibt.dropna(dim='storm', how='all', subset=['usa_wind']) # Much quicker to drop NaNs only at the end\n",
    "ds_ibt = ds_ibt.dropna(dim='storm', how='all', subset=['usa_rmw']) \n",
    "ds_ibt = ds_ibt.dropna(dim='storm', how='all', subset=['usa_r34'])\n",
    "\n",
    "print(\"Total samples after (1): \", len(ds_ibt['storm']))\n",
    "\n",
    "### 2) FINAL DATASET\n",
    "### Keep longest valid sequence if it represents more than 60% of the TC life cycle\n",
    "# Both for RMW and R34\n",
    "life_cyc_percent_thresh = 0.6\n",
    "\n",
    "for s in tqdm(range(len(ds_ibt['storm']))):\n",
    "        ds      = ds_ibt.isel(storm=s)\n",
    "        # Compute life cycle length\n",
    "        cyc_len = np.where(np.isnan(ds['usa_lat']))[0][0]\n",
    "        for param in ['usa_r34', 'usa_rmw']:\n",
    "            # Compute length of longest valid sequence\n",
    "            val_len = np.max(np.diff(np.concatenate(([0], np.where(np.isnan(ds[param]))[0]), axis=0)))\n",
    "            if val_len < life_cyc_percent_thresh * cyc_len:\n",
    "                # print('Index {}, Cyc_len = {}, val_len = {}'.format(s, cyc_len, val_len))\n",
    "                ds[param] *= np.nan\n",
    "                \n",
    "ds_ibt = ds_ibt.dropna(dim='storm', how='all', subset=['usa_rmw']) \n",
    "ds_ibt = ds_ibt.dropna(dim='storm', how='all', subset=['usa_r34'])\n",
    "\n",
    "print(\"Total samples after (2): \", len(ds_ibt['storm'])) \n",
    "\n",
    "### 3) ADD CORIOLIS\n",
    "ds_ibt['fcor'] = f.coriolis(np.abs(ds_ibt['usa_lat'])) * PARAMS['fcor_boost']\n",
    "                \n",
    "### 4) FLIP TCs of Southern hemisphere\n",
    "### Take the symmetric with respect to Equator\n",
    "### So storm_dir = PI - storm_dir\n",
    "ds_ibt.where(ds_ibt['lat'] < 0)['storm_dir'] = 180 - ds_ibt['storm_dir']\n",
    "# Then project to (u, v) ref.\n",
    "ds_ibt['u_trans'] = ds_ibt['storm_speed'] * np.sin(np.deg2rad(ds_ibt['storm_dir']))\n",
    "ds_ibt['v_trans'] = ds_ibt['storm_speed'] * np.cos(np.deg2rad(ds_ibt['storm_dir']))\n",
    "# plt.hist(np.array(ds_ibt['u_trans']).flatten()) # Check gaussianity\n",
    "\n",
    "### 5) COMPUTE RMAX_CK22\n",
    "ds_ibt['rmax_ck22'] = f.get_rmax_ck22(\n",
    "    Vmax=ds_ibt['usa_wind'], R17=ds_ibt['usa_r34'], fcor=f.coriolis(np.abs(ds_ibt['usa_lat'])), \n",
    "    intercept=0.459, coef1=0.00534, coef2=-0.00337\n",
    ") / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### SAVE CSV FILES - With Ck/Cd\n",
    "# for s in range(len(ds_ibt.storm)):\n",
    "#     ds         = ds_ibt.isel(storm=slice(s, s + 1))\n",
    "#     filename   = str(ds['name'].values)[2:-1] + '_' + str(ds['sid'].values)[2:-1]\n",
    "#     X_TC, _    = f.create_Xt_1_and_Xt_full(ds, final_params=['usa_wind', 'usa_rmw', 'rmax_ck22', 'usa_r34', 'fcor', 'u_trans', 'v_trans', 'mean_ck_cd'])\n",
    "#     X_TC       = X_TC[:, [0, 1, 2, 3, 4, 5, 6, 7]] # Select parameters\n",
    "#     df         = pd.DataFrame(X_TC)\n",
    "#     df.columns =  ['Vmax', 'Rmax_IBT', 'Rmax_CK22', 'R34', 'fcor', 'u_trans', 'v_trans', 'mean_ck_cd']\n",
    "#     df.to_csv(PATHS['save_csv_path'] + filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_ibt.isel(storm=-2)['mean_ck_cd'].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paramProfiles",
   "language": "python",
   "name": "paramprofiles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
